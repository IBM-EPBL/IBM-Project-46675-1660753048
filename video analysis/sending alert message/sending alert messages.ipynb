{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1HDWaJKv3Tm"
      },
      "outputs": [],
      "source": [
        "{\n",
        "  \"nbformat\": 4,\n",
        "  \"nbformat_minor\": 0,\n",
        "  \"metadata\": {\n",
        "    \"colab\": {\n",
        "      \"provenance\": []\n",
        "    },\n",
        "    \"kernelspec\": {\n",
        "      \"name\": \"python3\",\n",
        "      \"display_name\": \"Python 3\"\n",
        "    },\n",
        "    \"language_info\": {\n",
        "      \"name\": \"python\"\n",
        "    }\n",
        "  },\n",
        "  \"cells\": [\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"id\": \"8UJ9acdRwxAs\"\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"\\n\",\n",
        "        \"from google.colab import drive\\n\",\n",
        "        \"drive.mount('/content/drive')\\n\",\n",
        "        \"Mounted at /content/drive\\n\",\n",
        "        \"!pip install tensorflow\\n\",\n",
        "        \"!pip install opencv-python\\n\",\n",
        "        \"!pip install opencv-contrib-python\\n\",\n",
        "        \"import tensorflow as tf\\n\",\n",
        "        \"import numpy as np\\n\",\n",
        "        \"from tensorflow import keras\\n\",\n",
        "        \"import os\\n\",\n",
        "        \"import cv2\\n\",\n",
        "        \"from tensorflow.keras.preprocessing.image import ImageDataGenerator\\n\",\n",
        "        \"from tensorflow.keras.preprocessing import image\\n\",\n",
        "        \"Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\\n\",\n",
        "        \"Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\\n\",\n",
        "        \"Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\\n\",\n",
        "        \"Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\\n\",\n",
        "        \"Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\\n\",\n",
        "        \"Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\\n\",\n",
        "        \"Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\\n\",\n",
        "        \"Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\\n\",\n",
        "        \"Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\\n\",\n",
        "        \"Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\\n\",\n",
        "        \"Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\\n\",\n",
        "        \"Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\\n\",\n",
        "        \"Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.1.0)\\n\",\n",
        "        \"Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\\n\",\n",
        "        \"Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\\n\",\n",
        "        \"Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\\n\",\n",
        "        \"Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.1)\\n\",\n",
        "        \"Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\\n\",\n",
        "        \"Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\\n\",\n",
        "        \"Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\\n\",\n",
        "        \"Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\\n\",\n",
        "        \"Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\\n\",\n",
        "        \"Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\\n\",\n",
        "        \"Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\\n\",\n",
        "        \"Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.1)\\n\",\n",
        "        \"Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\\n\",\n",
        "        \"Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.35.0)\\n\",\n",
        "        \"Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\\n\",\n",
        "        \"Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\\n\",\n",
        "        \"Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\\n\",\n",
        "        \"Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\\n\",\n",
        "        \"Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\\n\",\n",
        "        \"Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\\n\",\n",
        "        \"Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\\n\",\n",
        "        \"Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.4)\\n\",\n",
        "        \"Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\\n\",\n",
        "        \"Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\\n\",\n",
        "        \"Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.13.0)\\n\",\n",
        "        \"Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.10.0)\\n\",\n",
        "        \"Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\\n\",\n",
        "        \"Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\\n\",\n",
        "        \"Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\\n\",\n",
        "        \"Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\\n\",\n",
        "        \"Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\\n\",\n",
        "        \"Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\\n\",\n",
        "        \"Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\\n\",\n",
        "        \"Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\\n\",\n",
        "        \"Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.6.0.66)\\n\",\n",
        "        \"Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.6)\\n\",\n",
        "        \"Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\\n\",\n",
        "        \"Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (4.6.0.66)\\n\",\n",
        "        \"Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python) (1.21.6)\\n\",\n",
        "        \"train=ImageDataGenerator(rescale=1./255,\\n\",\n",
        "        \"                                 shear_range=0.2,\\n\",\n",
        "        \"                                 rotation_range=180,\\n\",\n",
        "        \"                                 zoom_range=0.2,\\n\",\n",
        "        \"                                 horizontal_flip=True)\\n\",\n",
        "        \"train = ImageDataGenerator(rescale=1/255)\\n\",\n",
        "        \"test = ImageDataGenerator(rescale=1/255)\\n\",\n",
        "        \"train_dataset = train.flow_from_directory(\\\"/content/drive/MyDrive/Dataset/Dataset/train_set\\\",\\n\",\n",
        "        \"                                          target_size=(128,128),\\n\",\n",
        "        \"                                          batch_size = 32,\\n\",\n",
        "        \"                                          class_mode = 'binary' )\\n\",\n",
        "        \"Found 436 images belonging to 2 classes.\\n\",\n",
        "        \"test_dataset = test.flow_from_directory(\\\"/content/drive/MyDrive/Dataset/Dataset/test_set\\\",\\n\",\n",
        "        \"                                          target_size=(128,128),\\n\",\n",
        "        \"                                          batch_size = 32,\\n\",\n",
        "        \"                                          class_mode = 'binary' )\\n\",\n",
        "        \"Found 121 images belonging to 2 classes.\\n\",\n",
        "        \"test_dataset.class_indices\\n\",\n",
        "        \"{'forest': 0, 'with fire': 1}\\n\",\n",
        "        \"#to define linear initialisation import sequential\\n\",\n",
        "        \"from keras.models import Sequential\\n\",\n",
        "        \"#to add layer import Dense\\n\",\n",
        "        \"from keras.layers import Dense\\n\",\n",
        "        \"#to create convolution kernel import convolution2D\\n\",\n",
        "        \"from keras.layers import Convolution2D\\n\",\n",
        "        \"#import Maxpooling layer\\n\",\n",
        "        \"from keras.layers import MaxPooling2D\\n\",\n",
        "        \"#import flatten layer\\n\",\n",
        "        \"from keras.layers import Flatten\\n\",\n",
        "        \"import warnings\\n\",\n",
        "        \"warnings.filterwarnings('ignore')\\n\",\n",
        "        \"model = keras.Sequential()\\n\",\n",
        "        \"model.add(Convolution2D(32,(3,3),input_shape=(128,128,3),activation='relu'))\\n\",\n",
        "        \"model.add(MaxPooling2D(pool_size=(2,2)))\\n\",\n",
        "        \"model.add(Convolution2D(32,(3,3),activation='relu'))\\n\",\n",
        "        \"model.add(MaxPooling2D(pool_size=(2,2)))\\n\",\n",
        "        \"model.add(Convolution2D(32,(3,3),activation='relu'))\\n\",\n",
        "        \"model.add(MaxPooling2D(pool_size=(2,2)))\\n\",\n",
        "        \"model.add(Convolution2D(32,(3,3),activation='relu'))\\n\",\n",
        "        \"model.add(MaxPooling2D(pool_size=(2,2)))\\n\",\n",
        "        \"model.add(Flatten())\\n\",\n",
        "        \"model.add(Dense(150,activation='relu'))\\n\",\n",
        "        \"\\n\",\n",
        "        \"model.add(Dense(1,activation='sigmoid'))\\n\",\n",
        "        \"model.compile(loss = 'binary_crossentropy',\\n\",\n",
        "        \"              optimizer = \\\"adam\\\",\\n\",\n",
        "        \"              metrics = [\\\"accuracy\\\"])\\n\",\n",
        "        \"r = model.fit(train_dataset, epochs = 5, validation_data = test_dataset)\\n\",\n",
        "        \"Epoch 1/5\\n\",\n",
        "        \"14/14 [==============================] - 92s 7s/step - loss: 0.5798 - accuracy: 0.6628 - val_loss: 0.3330 - val_accuracy: 0.8595\\n\",\n",
        "        \"Epoch 2/5\\n\",\n",
        "        \"14/14 [==============================] - 26s 2s/step - loss: 0.4139 - accuracy: 0.8280 - val_loss: 0.1400 - val_accuracy: 0.9504\\n\",\n",
        "        \"Epoch 3/5\\n\",\n",
        "        \"14/14 [==============================] - 26s 2s/step - loss: 0.2800 - accuracy: 0.8922 - val_loss: 0.1375 - val_accuracy: 0.9587\\n\",\n",
        "        \"Epoch 4/5\\n\",\n",
        "        \"14/14 [==============================] - 27s 2s/step - loss: 0.2440 - accuracy: 0.9014 - val_loss: 0.1224 - val_accuracy: 0.9669\\n\",\n",
        "        \"Epoch 5/5\\n\",\n",
        "        \"14/14 [==============================] - 26s 2s/step - loss: 0.1856 - accuracy: 0.9243 - val_loss: 0.0586 - val_accuracy: 0.9752\\n\",\n",
        "        \"predictions = model.predict(test_dataset)\\n\",\n",
        "        \"predictions = np.round(predictions)\\n\",\n",
        "        \"4/4 [==============================] - 5s 1s/step\\n\",\n",
        "        \"predictions\\n\",\n",
        "        \"array([[0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.],\\n\",\n",
        "        \"       [1.],\\n\",\n",
        "        \"       [0.]], dtype=float32)\\n\",\n",
        "        \"print(len(predictions))\\n\",\n",
        "        \"121\\n\",\n",
        "        \"model.save(\\\"/content/drive/MyDrive/archive (1)/forest1.h5\\\")\\n\",\n",
        "        \"#import load_model from keras.model\\n\",\n",
        "        \"from keras.models import load_model\\n\",\n",
        "        \"#import image class from keras\\n\",\n",
        "        \"import tensorflow as tf\\n\",\n",
        "        \"from tensorflow.keras.preprocessing import image\\n\",\n",
        "        \"#import numpy\\n\",\n",
        "        \"import numpy as np\\n\",\n",
        "        \"#import cv2\\n\",\n",
        "        \"import cv2\\n\",\n",
        "        \"model = load_model(\\\"/content/drive/MyDrive/archive (1)/forest1.h5\\\")\\n\",\n",
        "        \"def predictImage(filename):\\n\",\n",
        "        \"  img1 = image.load_img(filename,target_size=(128,128))\\n\",\n",
        "        \"  Y = image.img_to_array(img1)\\n\",\n",
        "        \"  X = np.expand_dims(Y,axis=0)\\n\",\n",
        "        \"  val = model.predict(X)\\n\",\n",
        "        \"  print(val)\\n\",\n",
        "        \"  if val == 1:\\n\",\n",
        "        \"    print(\\\" fire\\\")\\n\",\n",
        "        \"  elif val == 0:\\n\",\n",
        "        \"      print(\\\"no fire\\\")\\n\",\n",
        "        \"predictImage(\\\"/content/drive/MyDrive/Dataset/Dataset/test_set/with fire/19464620_401.jpg\\\")\\n\",\n",
        "        \"1/1 [==============================] - 0s 125ms/step\\n\",\n",
        "        \"[[1.]]\\n\",\n",
        "        \" fire\\n\",\n",
        "        \"pip install twilio\\n\",\n",
        "        \"Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\\n\",\n",
        "        \"Collecting twilio\\n\",\n",
        "        \"  Downloading twilio-7.15.1-py2.py3-none-any.whl (1.4 MB)\\n\",\n",
        "        \"     |████████████████████████████████| 1.4 MB 4.9 MB/s \\n\",\n",
        "        \"Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from twilio) (2.23.0)\\n\",\n",
        "        \"Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from twilio) (2022.6)\\n\",\n",
        "        \"Collecting PyJWT<3.0.0,>=2.0.0\\n\",\n",
        "        \"  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\\n\",\n",
        "        \"Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->twilio) (2.10)\\n\",\n",
        "        \"Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->twilio) (3.0.4)\\n\",\n",
        "        \"Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->twilio) (1.24.3)\\n\",\n",
        "        \"Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->twilio) (2022.9.24)\\n\",\n",
        "        \"Installing collected packages: PyJWT, twilio\\n\",\n",
        "        \"Successfully installed PyJWT-2.6.0 twilio-7.15.1\\n\",\n",
        "        \"pip install playsound\\n\",\n",
        "        \"Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\\n\",\n",
        "        \"Collecting playsound\\n\",\n",
        "        \"  Downloading playsound-1.3.0.tar.gz (7.7 kB)\\n\",\n",
        "        \"Building wheels for collected packages: playsound\\n\",\n",
        "        \"  Building wheel for playsound (setup.py) ... done\\n\",\n",
        "        \"  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7035 sha256=6cc8a594765dc045811d54129bc5e3fbe95669eecf509234f657cb6a9be4eb0c\\n\",\n",
        "        \"  Stored in directory: /root/.cache/pip/wheels/ba/f8/bb/ea57c0146b664dca3a0ada4199b0ecb5f9dfcb7b7e22b65ba2\\n\",\n",
        "        \"Successfully built playsound\\n\",\n",
        "        \"Installing collected packages: playsound\\n\",\n",
        "        \"Successfully installed playsound-1.3.0\\n\",\n",
        "        \"#import opencv librariy\\n\",\n",
        "        \"import cv2\\n\",\n",
        "        \"#import numpy\\n\",\n",
        "        \"import numpy as np\\n\",\n",
        "        \"#import image function from keras\\n\",\n",
        "        \"from keras.preprocessing import image\\n\",\n",
        "        \"#import load_model from keras\\n\",\n",
        "        \"from keras.models import load_model\\n\",\n",
        "        \"#import client from twilio API\\n\",\n",
        "        \"from twilio.rest import Client\\n\",\n",
        "        \"#imort playsound package\\n\",\n",
        "        \"from playsound import playsound\\n\",\n",
        "        \"WARNING:playsound:playsound is relying on another python subprocess. Please use `pip install pygobject` if you want playsound to run more efficiently.\\n\",\n",
        "        \"#load the saved model\\n\",\n",
        "        \"model = load_model(r'/content/drive/MyDrive/archive (1)/forest1.h5')\\n\",\n",
        "        \"#define video\\n\",\n",
        "        \"video = cv2.VideoCapture('/content/Fighting Fire with Fire _ Explained in 30 Seconds.mp4')\\n\",\n",
        "        \"#define the features\\n\",\n",
        "        \"name = ['forest','with forest']\\n\",\n",
        "        \"account_sid = 'ACde2b15dad8f6e39c32b35eaa64921cf2'\\n\",\n",
        "        \"auth_token = '1928bb64202abc74a3ff94b70d5deec4'\\n\",\n",
        "        \"client = Client(account_sid, auth_token)\\n\",\n",
        "        \"\\n\",\n",
        "        \"message = client.messages \\\\\\n\",\n",
        "        \"    .create(\\n\",\n",
        "        \"         body='Forest fire is detected , stay alert',\\n\",\n",
        "        \"         from_='+16075363954',\\n\",\n",
        "        \"         to='+919488200286'\\n\",\n",
        "        \"     )\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(message.sid)\\n\",\n",
        "        \"SMcd33e58fa6f60aa349ecba81dce9b48d\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"PoMiIT1mw1xr\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    }\n",
        "  ]\n",
        "}"
      ]
    }
  ]
}